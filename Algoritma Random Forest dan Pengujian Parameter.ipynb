{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fungsi untuk menghitung Entropy\n",
    "def entropy(y):\n",
    "    #Mehitung jumlah kemunculan kelas, hasil berupa array [a, b]\n",
    "    kemunculan_kelas = np.bincount(y)\n",
    "    #Menghitung probabilitas kemunculan kelas, hasil berupa array [a, b]\n",
    "    prob_kemunculan = kemunculan_kelas/len(y)\n",
    "    #Return rumus entropy, dengan kondisi px tidak kurang dari 0\n",
    "    return -np.sum([px * np.log2(px) for px in prob_kemunculan if px > 0])\n",
    "\n",
    "#Kelas pembantu untuk menyimpan informasi node\n",
    "class Node:\n",
    "    #Parameter dari Node yang ada pada sebuah Decision Tree yang nilainya perlu disimpan\n",
    "    #* digunakan untuk keyword only parameter\n",
    "    def __init__(self, fitur=None, threshold=None, node_kiri=None, node_kanan=None, *, nilai_leaf=None):\n",
    "        self.fitur = fitur\n",
    "        self.threshold = threshold\n",
    "        self.node_kiri = node_kiri\n",
    "        self.node_kanan = node_kanan\n",
    "        self.nilai_leaf = nilai_leaf\n",
    "    \n",
    "    #Fungsi pembantu untuk mengindikasikan bawah proses spilitting sudah sampai di node leaf\n",
    "    def leaf_node(self):\n",
    "        return self.nilai_leaf is not None\n",
    "    \n",
    "#Kelas Decision Tree\n",
    "class DecisionTree:\n",
    "    #Constructor dengan parameter untuk proses splitting\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, jumlah_fitur=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.jumlah_fitur = jumlah_fitur\n",
    "        self.root = None\n",
    "    \n",
    "    #Fungsi untuk melakukan training \n",
    "    def fit(self, X, y):\n",
    "        #Jumlah fitur = jumlah kolom dari x yang dipilih\n",
    "        #Dengan kondisi jika nanti jumlah_fitur tidak didefinisikan maka jumlah fitur yang dipilih adalah jumlah maksimal dari fitur yang dipilih\n",
    "        #Dan jumlah fitur yang dipilih tidak akan lebih besar dari jumlah_fitur yang ada\n",
    "        self.jumlah_fitur = X.shape[1] if not self.jumlah_fitur else min(self.jumlah_fitur, X.shape[1])\n",
    "        #Memulai pembentukan decision tree dari root\n",
    "        self.root = self.tree(X, y)\n",
    "    \n",
    "    #Fungsi untuk membentuk decision tree\n",
    "    def tree(self, X, y, depth=0):\n",
    "        #Mendapatkan nilai dari jumlah sample/baris dan nilai dari jumlah fitur/kolom yang ada pada data hasil pre-processing\n",
    "        n_samples, n_fitur = X.shape\n",
    "        #Mendapatkan nilai dari total kelas yang ada pada data hasil pre-processing\n",
    "        n_kelas = len(np.unique(y))\n",
    "        \n",
    "        #Stopping criteria untuk proses splitting\n",
    "        #Jika kondisi terpenuhi\n",
    "        if (depth >= self.max_depth\n",
    "                or n_kelas == 1\n",
    "                or n_samples < self.min_samples_split):\n",
    "            #Maka proses splitting sudah sampai di leaf , dan nilai pada leaf bisa didapatkan menggunakan fungsi nilai_kelas_terbanyak\n",
    "            nilai_leaf_node = self.nilai_kelas_terbanyak(y)\n",
    "            #Menyimpan nilai leaf pada leaf_node\n",
    "            return Node(nilai_leaf=nilai_leaf_node)\n",
    "        \n",
    "       \n",
    "        #Memilih index secara random pada array n_fitur sejumlah jumlah_fitur tanpa pengembalian\n",
    "        fitur_dipilih = np.random.choice(n_fitur, self.jumlah_fitur, replace=False)\n",
    "        \n",
    "        #Mencari fitur terbaik dan threshold terbaik dari fitur yang telah dipilih secara random\n",
    "        fitur_terbaik, threshold_terbaik = self.feature_extraction(X, y, fitur_dipilih)\n",
    "        \n",
    "        #Membuat decision node berdasarkan rule (attribut dan threshold terbaik) yang telah dihitung melalui beberapa proses\n",
    "        #Memilih semua sample data pada fitur_terbaik\n",
    "        split_kiri, split_kanan = self.split(X[:, fitur_terbaik], threshold_terbaik)\n",
    "        #Memilih x dan y yang ada pada sample kiri untuk dijadikan sebagai sub decision node ( sudah dengan fitur dan threshold terbaik)\n",
    "        node_kiri = self.tree(X[split_kiri, :], y[split_kiri], depth+1)\n",
    "        #Memilih x dan y yang ada pada sample kanan  untuk dijadikan sebagai sub decision node ( sudah dengan fitur dan threshold terbaik)\n",
    "        node_kanan = self.tree(X[split_kanan, :], y[split_kanan], depth+1)\n",
    "        #Menyimpan nilai node\n",
    "        return Node(fitur_terbaik, threshold_terbaik, node_kiri, node_kanan)\n",
    "        \n",
    "    #Fungsi untuk mendapatkan fitur dan threshold terbaik\n",
    "    def feature_extraction(self, X, y, fitur_dipilih):\n",
    "        best_gain = -1\n",
    "        split_fitur, split_threshold = None, None\n",
    "        \n",
    "        for fitur_index in fitur_dipilih:\n",
    "            #Memilih kolom dari fitur yang dipilih\n",
    "            kolom_X = X[:, fitur_index]\n",
    "            #Mendapatkan nilai fitur yang dipilih/threshold secara unik\n",
    "            thresholds = np.unique(kolom_X)\n",
    "            for threshold in thresholds:\n",
    "                #Melakukan perhitungan entropy dan information gain untuk mendapatkan best threshold pada fungsi information_gain\n",
    "                gain = self.information_gain(y, kolom_X, threshold)\n",
    "                \n",
    "                #Kondisi untuk mendapatkan fitur dan threshold terbaik untuk dijadikan sebagai rule pada decision node\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_fitur = fitur_index\n",
    "                    split_threshold = threshold\n",
    "                    \n",
    "        return split_fitur, split_threshold\n",
    "        \n",
    "    #Fungsi untuk menghitung information gain\n",
    "    def information_gain(self, y, kolom_X, split_threshold):\n",
    "        #Menghitung parent entropy\n",
    "        parent_entropy = entropy(y)\n",
    "        \n",
    "        #Melakukan splitting dengan fungsi split\n",
    "        split_kiri, split_kanan = self.split(kolom_X, split_threshold)\n",
    "        \n",
    "        if len(split_kiri) == 0 or len(split_kanan) == 0:\n",
    "            return 0\n",
    "        \n",
    "        #Menghitung child entropy\n",
    "        total_kelas = len(y)\n",
    "        total_kelas_kiri = len(split_kiri)\n",
    "        total_kelas_kanan = len(split_kanan)\n",
    "        entropy_split_kiri = entropy(y[split_kiri])\n",
    "        entropy_split_kanan = entropy(y[split_kanan])\n",
    "        child_entropy = (total_kelas_kiri / total_kelas) * entropy_split_kiri + (total_kelas_kanan / total_kelas) * entropy_split_kanan\n",
    "        \n",
    "        #Information Gain\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "        \n",
    "    #Fungsi untuk splitting    \n",
    "    def split(self, kolom_X, split_threshold):\n",
    "        split_kiri = np.argwhere(kolom_X <= split_threshold).flatten()\n",
    "        split_kanan = np.argwhere(kolom_X > split_threshold).flatten()\n",
    "        return split_kiri, split_kanan\n",
    "        \n",
    "        \n",
    "    #Fungsi untuk mendapatkan nilai kelas terbanyak pada leaf node\n",
    "    def nilai_kelas_terbanyak(self, y):\n",
    "        #Menghitung jumlah kemunculan kelas pada leaf node\n",
    "        counter = Counter(y)\n",
    "        #Mendapatkan nilai kemunculan kelas terbanyak\n",
    "        kemunculan_kelas_terbanyak = counter.most_common(1)[0][0]\n",
    "        #Menyimpan nilai tersebut untuk di pass\n",
    "        return kemunculan_kelas_terbanyak\n",
    "    \n",
    "    #Fungsi untuk melakukan prediksi\n",
    "    def predict(self, X):\n",
    "        #Memasukan satu per satu data testing yang ada pada input data ke dalam decision tree dimulai dari root node\n",
    "        return np.array([self.pergerakan_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def pergerakan_tree(self, x, node):\n",
    "        #Jika sampai di leaf node nilai_leaf didapatkan\n",
    "        if node.leaf_node():\n",
    "            return node.nilai_leaf\n",
    "        #Jika belum akan ke kiri jika threshold data testing <= threshold rule\n",
    "        if x[node.fitur] <= node.threshold:\n",
    "            return self.pergerakan_tree(x, node.node_kiri)\n",
    "        #Ke kanan jika threshold data testing > threshold rule\n",
    "        return self.pergerakan_tree(x, node.node_kanan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_dataset(X, y):\n",
    "        #Mendapatkan baris data X\n",
    "        sampel_data = X.shape[0]\n",
    "        #Memilih Index secara random dari array sampel data sejumlah sampel_data dengan pengembalian\n",
    "        bootstrap_data = np.random.choice(sampel_data, size=sampel_data, replace=True)\n",
    "        #Menyimpan nilai yang dipilih\n",
    "        return X[bootstrap_data], y[bootstrap_data]\n",
    "    \n",
    "def voting(y):\n",
    "        #Menghitung kemunculan kelas\n",
    "        counter = Counter(y)\n",
    "        #Mendapatkan nilai kemunculan kelas terbanyak\n",
    "        kemunculan_kelas_terbanyak = counter.most_common(1)[0][0]\n",
    "        #Menyimpan nilai tersebut untuk di pass\n",
    "        return kemunculan_kelas_terbanyak\n",
    "    \n",
    "class RandomForest:\n",
    "    #self untuk mengakses attribut dan fungsi yang ada di dalam kelas\n",
    "    def __init__(self, jumlah_tree, min_samples_split=2, max_depth=100, jumlah_fitur=None):\n",
    "        self.jumlah_tree = jumlah_tree\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.jumlah_fitur = jumlah_fitur\n",
    "        self.array_tree = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #Melakukan training terhadap setiap decision dari sejumlah n decision tree berdasarkan bootstrapped dataset\n",
    "        for single_tree in range(self.jumlah_tree):\n",
    "            # Memanggil kelas Decision tree\n",
    "            tree = DecisionTree(min_samples_split=self.min_samples_split, max_depth=self.max_depth, jumlah_fitur=self.jumlah_fitur)\n",
    "            # memasukan nilai x dan y bootsrap data ke dalam variabel\n",
    "            X_subset, y_subset = bootstrapped_dataset(X, y)\n",
    "            # melatih tree berdasarkan x dan y bootstrapped dataset\n",
    "            tree.fit(X_subset, y_subset)\n",
    "            #Menambahkan decision tree hasil training ke dalam array tree\n",
    "            self.array_tree.append(tree)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        #proses prediksi berulang\n",
    "        tree_prediksi = np.array([tree.predict(X) for tree in self.array_tree])\n",
    "        #misal hasil prediksi ([[1, 0, 1, 0],[1, 1, 1, 1], [1, 0, 1, 0]])\n",
    "        #diubah menjadi\n",
    "        #([[1, 1, 1]\n",
    "        #   0, 1, 0\n",
    "        #   1, 1, 1\n",
    "        #   0, 1, 0])\n",
    "        tree_prediksi = np.swapaxes(tree_prediksi, 0, 1)\n",
    "        #Melakukan voting dari n decision tree yang telah dibangun\n",
    "        prediksi_y = [voting(sekumpulan_tree) for sekumpulan_tree in tree_prediksi]\n",
    "        #Menyimpan nilai\n",
    "        return np.array(prediksi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date  Open  High   Low  Close    Upper Band    Lower Band  \\\n",
      "19    Apr 24, 2012  3925  3925  3875   3875  4.091305e+09  3.818695e+09   \n",
      "20    Apr 25, 2012  3875  3925  3875   3900  4.087802e+09  3.809698e+09   \n",
      "21    Apr 26, 2012  3900  4075  3900   4050  4.085113e+09  3.804887e+09   \n",
      "22    Apr 27, 2012  4050  4075  3975   4000  4.098573e+09  3.803927e+09   \n",
      "23    Apr 30, 2012  4000  4025  3975   4025  4.101090e+09  3.803910e+09   \n",
      "...            ...   ...   ...   ...    ...           ...           ...   \n",
      "2208  Apr 27, 2021  5800  5900  5750   5900  6.042998e+09  5.662002e+09   \n",
      "2209  Apr 28, 2021  5900  5900  5800   5825  6.026606e+09  5.668394e+09   \n",
      "2210  Apr 29, 2021  5875  5925  5825   5875  6.029306e+09  5.673194e+09   \n",
      "2211  Apr 30, 2021  5875  5875  5650   5700  6.026769e+09  5.690731e+09   \n",
      "2212  May 03, 2021  5700  5725  5550   5575  6.033885e+09  5.676115e+09   \n",
      "\n",
      "                %K            %D  Relative Strength Index    SMA5   SMA 20  \\\n",
      "19    3.076923e+09  2.692308e+09             4.274441e+08  3930.0  3955.00   \n",
      "20    2.222222e+09  2.599715e+07             4.515755e+09  3920.0  3948.75   \n",
      "21    3.000000e+01  2.766382e+09             5.689613e+09  3910.0  3945.00   \n",
      "22    9.000000e+01  4.740741e+09             5.283641e+09  3935.0  3951.25   \n",
      "23    7.000000e+01  6.333333e+09             5.458144e+08  3950.0  3952.50   \n",
      "...            ...           ...                      ...     ...      ...   \n",
      "2208  3.333333e+09  2.777778e+09             5.053293e+09  5800.0  5852.50   \n",
      "2209  5.555556e+09  4.444444e+09             4.759886e+09  5805.0  5847.50   \n",
      "2210  5.625000e+01  4.837963e+09             4.969584e+09  5820.0  5851.25   \n",
      "2211  5.625000e+01  5.601852e+09             4.318238e+09  5860.0  5858.75   \n",
      "2212  3.000000e+01  4.750000e+01             3.922745e+09  5830.0  5855.00   \n",
      "\n",
      "           Chaikin        OBV            %R  Kelas  \n",
      "19    1.845072e+09   73560000  6.923077e+09    0.0  \n",
      "20    1.644696e+09   67180000  7.777778e+09    0.0  \n",
      "21    1.399731e+09  109530000  7.000000e+01    1.0  \n",
      "22    1.479798e+09  122460000  1.000000e+01    1.0  \n",
      "23    1.645644e+09   88130000  3.000000e+01    0.0  \n",
      "...            ...        ...           ...    ...  \n",
      "2208  6.356712e+09  879590000  6.666667e+09    0.0  \n",
      "2209  6.285850e+09  897020000  4.444444e+09    1.0  \n",
      "2210  5.863395e+09  885720000  4.375000e+01    0.0  \n",
      "2211  7.012457e+09  885720000  4.375000e+01    1.0  \n",
      "2212  7.975568e+09  862010000  7.000000e+01    0.0  \n",
      "\n",
      "[2194 rows x 16 columns]\n",
      "2194\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_excel('DataSaham.xlsx')\n",
    "data = data1.dropna()\n",
    "data.head()\n",
    "print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.09130461e+09 3.81869539e+09 3.07692308e+09 ... 1.84507207e+09\n",
      "  7.35600000e+07 6.92307692e+09]\n",
      " [4.08780224e+09 3.80969776e+09 2.22222222e+09 ... 1.64469584e+09\n",
      "  6.71800000e+07 7.77777778e+09]\n",
      " [4.08511274e+09 3.80488726e+09 3.00000000e+01 ... 1.39973094e+09\n",
      "  1.09530000e+08 7.00000000e+01]\n",
      " ...\n",
      " [5.20718024e+09 4.71781976e+09 2.23684210e+09 ... 3.32770577e+09\n",
      "  2.65910000e+08 7.76315790e+09]\n",
      " [5.16656387e+09 4.72543613e+09 3.28947368e+09 ... 3.00345086e+09\n",
      "  2.78380000e+08 6.71052632e+09]\n",
      " [5.15429899e+09 4.72020101e+09 3.42105263e+09 ... 2.74377514e+09\n",
      "  2.93750000e+08 6.57894737e+09]]\n",
      "[0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1\n",
      " 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0\n",
      " 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1\n",
      " 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1\n",
      " 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0\n",
      " 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1\n",
      " 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "ArrayData = np.array(data)\n",
    "x = ArrayData[:500,5:15]\n",
    "X = x.astype(float)\n",
    "Y_1D = ArrayData[:500,15:16]\n",
    "y_new = Y_1D.ravel()\n",
    "y = y_new.astype(int)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForest(jumlah_tree=100, max_depth=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print (\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.64\n",
      "Precision : 0.7021276595744681\n",
      "Recall : 0.717391304347826\n",
      "F1 Score : 0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "rf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#display(rf_matrix)\n",
    "\n",
    "true_negative = rf_matrix[0][0]\n",
    "false_negative = rf_matrix[1][0]\n",
    "true_positive = rf_matrix[1][1]\n",
    "false_positive = rf_matrix[0][1]\n",
    "\n",
    "accuracy = (true_negative + true_positive) / (true_negative + false_negative + true_positive + false_positive)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "#specifity = true_negative / (true_negative + false_positive)\n",
    "F1_Score = 2 * (recall * precision) / (recall + precision)\n",
    "\n",
    "print('Accuracy :',format(float(accuracy)))\n",
    "print('Precision :',format(float(precision)))\n",
    "print('Recall :',format(float(recall)))\n",
    "#print('Specifity : ',format(float(specifity)))\n",
    "print('F1 Score :',format(float(F1_Score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Upper Band    Lower Band    Attribut 3    Attribut 4    Attribut 5  \\\n",
      "0    4.814278e+08  3.318222e+08  4.615385e+09  4.715667e+09  5.423329e+09   \n",
      "1    4.820224e+09  3.344776e+09  1.025641e+09  3.628976e+08  4.811226e+09   \n",
      "2    4.800734e+09  3.421766e+09  2.702703e+09  1.970432e+08  5.310021e+09   \n",
      "3    4.802049e+09  3.490451e+09  2.702703e+09  1.332871e+09  5.378371e+09   \n",
      "4    4.778967e+09  3.588533e+09  2.432432e+09  1.801802e+09  5.449785e+08   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "145  5.253345e+09  4.746155e+09  2.105263e+09  1.659919e+09  3.984196e+09   \n",
      "146  5.219691e+09  4.732309e+09  7.894737e+09  1.666667e+09  4.317015e+09   \n",
      "147  5.207180e+09  4.717820e+09  2.236842e+09  1.710526e+09  4.636568e+08   \n",
      "148  5.166564e+09  4.725436e+09  3.289474e+09  2.105263e+09  4.676861e+09   \n",
      "149  5.154299e+09  4.720201e+09  3.421053e+09  2.982456e+08  4.602390e+09   \n",
      "\n",
      "     Attribut 6  Attribut 7    Attribut 8   Attribut 9   Attribut 10  \\\n",
      "0        4260.0     4066.25  6.035529e+09   78840000.0  5.384615e+09   \n",
      "1        4225.0     4082.50  5.537030e+09   57260000.0  8.974359e+09   \n",
      "2        4180.0     4111.25  4.823448e+09   37510000.0  9.729730e+08   \n",
      "3        4225.0     4146.25  4.248863e+09   44040000.0  7.297297e+09   \n",
      "4        4230.0     4183.75  3.723974e+09   31670000.0  7.567568e+09   \n",
      "..          ...         ...           ...          ...           ...   \n",
      "145      4843.0     4999.75  4.013146e+09  265390000.0  7.894737e+09   \n",
      "146      4822.0     4976.00  3.623311e+09  245250000.0  9.210526e+09   \n",
      "147      4816.0     4962.50  3.327706e+09  265910000.0  7.763158e+09   \n",
      "148      4825.0     4946.00  3.003451e+09  278380000.0  6.710526e+09   \n",
      "149      4835.0     4937.25  2.743775e+09  293750000.0  6.578947e+09   \n",
      "\n",
      "     Kelas Sebenarnya  Kelas Prediksi Kesimpulan  \n",
      "0                   0               1      FALSE  \n",
      "1                   1               1       TRUE  \n",
      "2                   0               1      FALSE  \n",
      "3                   1               1       TRUE  \n",
      "4                   1               0      FALSE  \n",
      "..                ...             ...        ...  \n",
      "145                 0               0       TRUE  \n",
      "146                 1               0      FALSE  \n",
      "147                 1               0      FALSE  \n",
      "148                 1               1       TRUE  \n",
      "149                 1               0      FALSE  \n",
      "\n",
      "[150 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#Mengembalikan copy an array dari data y_test dan y_predict ke dalam bentuk 1 dimensi\n",
    "a = y_test.flatten()\n",
    "b = y_pred.flatten()\n",
    "c = np.where(a==b,\"TRUE\",\"FALSE\")\n",
    "index_1 = X_test[:,:1]\n",
    "index_1_flat = index_1.flatten()\n",
    "index_2 = X_test[:,1:2]\n",
    "index_2_flat = index_2.flatten()\n",
    "index_3 = X_test[:,2:3]\n",
    "index_3_flat = index_3.flatten()\n",
    "index_4 = X_test[:,3:4]\n",
    "index_4_flat = index_4.flatten()\n",
    "index_5 = X_test[:,4:5]\n",
    "index_5_flat = index_5.flatten()\n",
    "index_6 = X_test[:,5:6]\n",
    "index_6_flat = index_6.flatten()\n",
    "index_7 = X_test[:,6:7]\n",
    "index_7_flat = index_7.flatten()\n",
    "index_8 = X_test[:,7:8]\n",
    "index_8_flat = index_8.flatten()\n",
    "index_9 = X_test[:,8:9]\n",
    "index_9_flat = index_9.flatten()\n",
    "index_10 = X_test[:,9:10]\n",
    "index_10_flat = index_10.flatten()\n",
    "df = pd.DataFrame({'Upper Band': index_1_flat, 'Lower Band': index_2_flat,\n",
    "                   'Attribut 3': index_3_flat, 'Attribut 4': index_4_flat,\n",
    "                   'Attribut 5': index_5_flat, 'Attribut 6': index_6_flat,\n",
    "                   'Attribut 7': index_7_flat, 'Attribut 8': index_8_flat,\n",
    "                   'Attribut 9': index_9_flat, 'Attribut 10': index_10_flat,\n",
    "                   'Kelas Sebenarnya': a, 'Kelas Prediksi': b, 'Kesimpulan': c.flatten()})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
